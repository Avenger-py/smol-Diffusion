{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import scipy\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from diffusion import Diffusion\n",
    "from model import Unet, get_num_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    img_size = 64\n",
    "    batch_size = 32\n",
    "    T = 1000 # timesteps for training\n",
    "    sample_T = 15000 # timesteps for sampling\n",
    "    device = \"cuda\"\n",
    "    lr = 0.001\n",
    "    time_embd_dim = 32\n",
    "    steps = 100\n",
    "    max_iters = steps * (16000 // batch_size) # num iterations through all batches in dataset (total imgs ~ 16k) \n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_root_dir = \"data\"\n",
    "dataset = torchvision.datasets.StanfordCars(data_root_dir)\n",
    "show_images(dataset, num_samples=4, cols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_transformed_dataset(config.img_size, data_root_dir)\n",
    "# tiny_data = torch.utils.data.Subset(data, range(8))\n",
    "train_dataloader = DataLoader(data, batch_size=config.batch_size, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = next(iter(train_dataloader))[0]\n",
    "show_tensor_image(img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model and load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(time_embd_dim=config.time_embd_dim)\n",
    "model.to(config.device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"unet_diffusion_v2_ep99999.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=config.device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "print(f\"\\nCheckpoint loaded from path --> {ckpt_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_trainable_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Diffusion class, visualize & test forward & reverse diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = Diffusion(timesteps=config.T, img_size=config.img_size, device=config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate forward diffusion\n",
    "image = next(iter(train_dataloader))[0]\n",
    "diff.vis_forward_diffusion(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate & test reverse diffusion\n",
    "t_test = torch.full((1,), 100, device=config.device, dtype=torch.long)\n",
    "diff.test_reverse_diffusion(t_test, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(dataloader):\n",
    "    return next(iter(dataloader))\n",
    "\n",
    "def get_loss(model, x_0, t):\n",
    "    mse = nn.MSELoss()\n",
    "    x_noisy, noise = diff.forward_diffusion_sample(x_0, t)\n",
    "    noise_pred = model(x_noisy, t)\n",
    "    return mse(noise, noise_pred)\n",
    "\n",
    "\n",
    "def save_checkpoint(path, itr, loss):\n",
    "    torch.save({\n",
    "        \"model\": model.state_dict(),\n",
    "        \"config\": config,\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"epoch\": itr,\n",
    "        \"loss\": loss,\n",
    "    }, path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def train(model, optimizer, dataloader, iters, T, batch_size=config.batch_size, diffusion=None):\n",
    "    losses = []\n",
    "    for itr in tqdm(range(iters)):\n",
    "        optimizer.zero_grad()\n",
    "        t = torch.randint(0, T, (batch_size,), device=config.device).long()\n",
    "        x_0 = get_batch(dataloader)[0]\n",
    "        loss = get_loss(model, x_0, t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if itr % (iters // 5) == 0 or itr == iters - 1:\n",
    "            path = f\"unet_diffusion_v3_ep{itr}.pt\"\n",
    "            save_checkpoint(path, itr, loss.item())\n",
    "        \n",
    "        if itr % (iters // 50)  == 0:\n",
    "            print(f\"Epoch {itr} | Loss: {loss.item()} \")\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        if (itr % (iters // 10) == 0) or itr == iters - 1 :\n",
    "            diff.sample_plot_image(model)\n",
    "              \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "losses = train(model=model, optimizer=optimizer, dataloader=train_dataloader, \n",
    "                   iters=config.max_iters, T=config.T, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff2 = Diffusion(timesteps=config.sample_T, img_size=config.img_size, device=config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "num_samples = 5\n",
    "with torch.no_grad():\n",
    "    for j in range(num_samples):\n",
    "        img_size = config.img_size\n",
    "        img = torch.randn((1, 3, img_size, img_size), device=config.device)\n",
    "        plt.figure(figsize=(15,2))\n",
    "        plt.axis('off')\n",
    "        num_images = 10\n",
    "        stepsize = int(config.sample_T/num_images)\n",
    "        \n",
    "        for i in tqdm(range(0,config.sample_T)[::-1]):\n",
    "            t = torch.full((1,), i, device=config.device, dtype=torch.long)\n",
    "            img = diff2.sample_timestep(model, img, t)\n",
    "            img = torch.clamp(img, -1.0, 1.0)\n",
    "            if i % stepsize == 0:\n",
    "                plt.subplot(1, num_images, int(i/stepsize)+1)\n",
    "                show_tensor_image(img.detach().cpu())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5203439,
     "sourceId": 8680060,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 55843,
     "sourceId": 66967,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 56102,
     "sourceId": 67300,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 57467,
     "sourceId": 68908,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 57469,
     "sourceId": 68910,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 57625,
     "sourceId": 69084,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
